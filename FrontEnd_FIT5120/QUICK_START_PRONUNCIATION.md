# ğŸš€ Quick Start - Pronunciation Assessment Feature

## TÃ³m táº¯t: TÃ­nh nÄƒng Ä‘Ã£ hoÃ n thÃ nh

âœ… **Composable**: `useSpeechRecognition.js` - Quáº£n lÃ½ ghi Ã¢m vÃ  nháº­n diá»‡n giá»ng nÃ³i
âœ… **Service**: `azureSpeechService.js` - TÃ­ch há»£p Azure Speech API
âœ… **Component**: `Flashcard.vue` - UI cho flashcard vá»›i nÃºt "Talk"
âœ… **Fallback**: Tá»± Ä‘á»™ng chuyá»ƒn vá» Web Speech API náº¿u Azure khÃ´ng kháº£ dá»¥ng

---

## âš¡ CÃ i Ä‘áº·t nhanh (5 phÃºt)

### 1. Clone vÃ  cÃ i dependencies
```powershell
cd "c:\Users\WIN10\OneDrive\Desktop\Monash Project_5120\FIT5120-project\FrontEnd_FIT5120"
npm install
```

### 2. Cáº¥u hÃ¬nh Azure (Optional - bá» qua náº¿u chá»‰ test)
```powershell
# Copy .env.example sang .env
Copy-Item .env.example .env
```

Má»Ÿ `.env` vÃ  thÃªm (náº¿u cÃ³ Azure account):
```env
VITE_AZURE_SPEECH_KEY=your_key_here
VITE_AZURE_SPEECH_REGION=eastus
```

### 3. Cháº¡y project
```powershell
npm run dev
```

### 4. Test ngay
1. Má»Ÿ browser: `http://localhost:5173`
2. VÃ o **Learn English** â†’ Chá»n language â†’ Chá»n category
3. Click **Talk** button â†’ NÃ³i cÃ¢u tiáº¿ng Anh â†’ Xem káº¿t quáº£

---

## ğŸ“ Files Ä‘Ã£ táº¡o

### Core Files:
```
src/
â”œâ”€â”€ composables/
â”‚   â””â”€â”€ useSpeechRecognition.js       â† Speech recognition logic
â”œâ”€â”€ services/
â”‚   â””â”€â”€ azureSpeechService.js         â† Azure API integration
â””â”€â”€ components/
    â””â”€â”€ Flashcard.vue                 â† Updated with Talk button

Root:
â”œâ”€â”€ .env                              â† Azure credentials (don't commit!)
â”œâ”€â”€ .env.example                      â† Template for .env
â”œâ”€â”€ AZURE_SPEECH_SETUP.md             â† Chi tiáº¿t setup Azure
â”œâ”€â”€ PRONUNCIATION_GUIDE.md            â† User guide
â””â”€â”€ TESTING_GUIDE.md                  â† Test cases
```

---

## ğŸ¯ CÃ¡ch sá»­ dá»¥ng trong code

### Import composable:
```javascript
import { useSpeechRecognition } from '@/composables/useSpeechRecognition.js'

const {
  isRecording,
  pronunciationScore,
  startRecordingWebAPI,
  startRecordingForAzure,
  stopRecording,
  evaluatePronunciation
} = useSpeechRecognition()
```

### Import Azure service:
```javascript
import { assessPronunciation, isAzureConfigured } from '@/services/azureSpeechService.js'

// Check if Azure is configured
if (isAzureConfigured()) {
  // Use Azure
  const result = await assessPronunciation(audioBlob, referenceText, 'en-US')
} else {
  // Fallback to Web Speech API
}
```

---

## ğŸ”§ Configuration

### Environment Variables:
```env
# Required for Azure (optional)
VITE_AZURE_SPEECH_KEY=your_subscription_key
VITE_AZURE_SPEECH_REGION=eastus

# Optional
VITE_API_BASE_URL=http://localhost:3000
```

### Supported Regions:
- `eastus` (US East)
- `westus` (US West)
- `southeastasia` (Singapore)
- `westeurope` (Netherlands)
- `australiaeast` (Sydney)

Full list: https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/regions

---

## ğŸ¨ UI Components

### Talk Button:
```vue
<button class="talk-btn" @click.stop="handleTalk" :disabled="isRecording || isAssessing">
  {{ isRecording ? 'Recording...' : isAssessing ? 'Assessing...' : 'Talk' }}
</button>
```

### Pronunciation Result:
```vue
<div v-if="pronunciationResult" class="pronunciation-result" :class="`result-${pronunciationResult.level}`">
  <div class="result-score">
    <span class="score-value">{{ pronunciationResult.score }}</span>
    <span class="score-label">/100</span>
  </div>
  <div class="result-feedback">{{ pronunciationResult.feedback }}</div>
</div>
```

---

## ğŸ“Š API Response Format

### Azure Speech Service Response:
```javascript
{
  success: true,
  score: 85,                    // Overall score (0-100)
  accuracyScore: 87,            // Pronunciation accuracy
  fluencyScore: 84,             // Speech fluency
  completenessScore: 90,        // Completeness of speech
  confidence: 95,               // Confidence level
  transcribed: "Hello world",   // What user said
  reference: "Hello world",     // Expected text
  feedback: "Great job!",       // User-friendly message
  level: "great"                // excellent|great|good|fair|needs-improvement
}
```

### Web Speech API Response:
```javascript
{
  success: true,
  score: 78,
  similarity: 78,               // Text similarity (Levenshtein)
  confidence: 100,
  reference: "Hello world",
  transcribed: "Hello world",
  feedback: "Good!",
  level: "good"
}
```

---

## ğŸš¨ Error Handling

### Common Errors:

**1. Microphone Access Denied**
```javascript
{
  success: false,
  score: 0,
  feedback: "Microphone access denied",
  level: "error"
}
```

**2. Azure API Error**
```javascript
{
  success: false,
  score: 0,
  feedback: "Azure Speech API error: Invalid key",
  level: "error"
}
```

**3. No Speech Recognized**
```javascript
{
  success: false,
  score: 0,
  feedback: "Could not recognize speech. Please try again.",
  level: "error"
}
```

---

## ğŸ“ Code Examples

### Example 1: Basic Usage (Web Speech API)
```javascript
const handleTalk = async () => {
  // Start recording
  await startRecordingWebAPI('en-US')
  
  // Wait for result
  await waitForRecognition()
  
  // Evaluate
  if (recognitionResult.value?.text) {
    const result = evaluatePronunciation(
      referenceText,
      recognitionResult.value.text,
      recognitionResult.value.confidence
    )
    console.log('Score:', result.score)
  }
}
```

### Example 2: Azure Integration
```javascript
const handleTalkWithAzure = async () => {
  // Start recording
  await startRecordingForAzure()
  
  // Record for 5 seconds
  await new Promise(resolve => setTimeout(resolve, 5000))
  
  // Stop and get audio
  stopRecording()
  const audioBlob = await getAudioBlob()
  
  // Send to Azure
  const result = await assessPronunciation(
    audioBlob,
    referenceText,
    'en-US'
  )
  
  console.log('Azure Score:', result.score)
  console.log('Accuracy:', result.accuracyScore)
  console.log('Fluency:', result.fluencyScore)
}
```

---

## ğŸ§ª Quick Test

### Test with Console:
```javascript
// In browser console
const test = async () => {
  const { useSpeechRecognition } = await import('/src/composables/useSpeechRecognition.js')
  const { startRecordingWebAPI, recognitionResult } = useSpeechRecognition()
  
  await startRecordingWebAPI('en-US')
  console.log('Say something...')
  
  setTimeout(() => {
    console.log('Result:', recognitionResult.value)
  }, 5000)
}

test()
```

---

## ğŸ“š Documentation Links

- **Azure Speech Setup**: [`AZURE_SPEECH_SETUP.md`](./AZURE_SPEECH_SETUP.md)
- **User Guide**: [`PRONUNCIATION_GUIDE.md`](./PRONUNCIATION_GUIDE.md)
- **Testing Guide**: [`TESTING_GUIDE.md`](./TESTING_GUIDE.md)
- **Azure Docs**: https://learn.microsoft.com/en-us/azure/ai-services/speech-service/
- **Web Speech API**: https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API

---

## ğŸ”’ Security Best Practices

1. **Never commit `.env` file**
   - Already in `.gitignore`
   - Use `.env.example` as template

2. **Rotate Azure keys regularly**
   - Azure Portal â†’ Keys â†’ Regenerate

3. **Use environment variables in production**
   - Deploy with proper env vars
   - Don't hardcode keys in code

4. **Limit API usage**
   - Monitor Azure dashboard
   - Set up budget alerts

---

## ğŸ› Troubleshooting

### Problem: Talk button not working
**Solution**: Check browser console for errors, ensure microphone permissions granted

### Problem: Always getting 0 score
**Solution**: Check if speech is being recognized, try speaking louder and clearer

### Problem: Azure not working
**Solution**: 
1. Check `.env` file has correct keys
2. Verify region matches Azure Portal
3. Restart dev server after changing `.env`
4. Check Azure quota not exceeded

### Problem: "import.meta.env is undefined"
**Solution**: Using Vite, ensure you're using `VITE_` prefix for env vars

---

## ğŸ“¦ Build for Production

```powershell
# Build
npm run build

# Preview production build
npm run preview
```

**Important**: Set environment variables in your hosting platform (Vercel, Netlify, etc.)

---

## âœ… Checklist

Before deploying:
- [ ] `.env` file not committed
- [ ] Azure keys configured (or fallback to Web Speech)
- [ ] Tested on Chrome, Edge
- [ ] Tested on mobile device
- [ ] Error handling works
- [ ] All test cases passed

---

**Ready to go! ğŸ‰**

Questions? Check the documentation files or create an issue on GitHub.
